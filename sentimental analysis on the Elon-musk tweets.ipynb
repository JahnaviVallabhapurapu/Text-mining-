{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81d555b6",
   "metadata": {},
   "source": [
    "For Text Mining assignment\n",
    "\n",
    " Perform sentimental analysis on the Elon-musk tweets (Exlon-musk.csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "513285a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\saiki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a38669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\saiki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51631d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\saiki\\anaconda3\\lib\\site-packages (0.17.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\saiki\\anaconda3\\lib\\site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\saiki\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\saiki\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\saiki\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\saiki\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\saiki\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89627b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfecd39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>1995</td>\n",
       "      <td>@flcnhvy True, it sounds so surreal, but the n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>@PPathole Make sure to read ur terms &amp;amp; con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>@TeslaGong @PPathole Samwise Gamgee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>@PPathole Altho Dumb and Dumber is &lt;U+0001F525...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>Progress update August 28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               Text\n",
       "0              1                             @kunalb11 Im an alien\n",
       "1              2  @ID_AA_Carmack Ray tracing on Cyberpunk with H...\n",
       "2              3                @joerogan @Spotify Great interview!\n",
       "3              4                    @gtera27 Doge is underestimated\n",
       "4              5  @teslacn Congratulations Tesla China for amazi...\n",
       "...          ...                                                ...\n",
       "1994        1995  @flcnhvy True, it sounds so surreal, but the n...\n",
       "1995        1996  @PPathole Make sure to read ur terms &amp; con...\n",
       "1996        1997                @TeslaGong @PPathole Samwise Gamgee\n",
       "1997        1998  @PPathole Altho Dumb and Dumber is <U+0001F525...\n",
       "1998        1999                          Progress update August 28\n",
       "\n",
       "[1999 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"Elon_musk.csv\", encoding='latin1')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f5e35",
   "metadata": {},
   "source": [
    "2. Number of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "682a593b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  word_count\n",
       "0                             @kunalb11 Im an alien           4\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...          13\n",
       "2                @joerogan @Spotify Great interview!           4\n",
       "3                    @gtera27 Doge is underestimated           4\n",
       "4  @teslacn Congratulations Tesla China for amazi...          17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of Words in single tweet\n",
    "data['word_count'] = data['Text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "data[['Text','word_count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9391cafb",
   "metadata": {},
   "source": [
    "3. Number of Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cc5ceed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  char_count\n",
       "0                             @kunalb11 Im an alien          22\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...          82\n",
       "2                @joerogan @Spotify Great interview!          35\n",
       "3                    @gtera27 Doge is underestimated          31\n",
       "4  @teslacn Congratulations Tesla China for amazi...         104"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of characters in single tweet\n",
    "data['char_count'] = data['Text'].str.len() ## this also includes spaces\n",
    "data[['Text','char_count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4901aca4",
   "metadata": {},
   "source": [
    "4. Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44e74ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>avg_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>4.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>5.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>5.176471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  avg_word\n",
       "0                             @kunalb11 Im an alien  4.750000\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...  5.384615\n",
       "2                @joerogan @Spotify Great interview!  8.000000\n",
       "3                    @gtera27 Doge is underestimated  7.000000\n",
       "4  @teslacn Congratulations Tesla China for amazi...  5.176471"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_word(sentence):\n",
    "  words = sentence.split()\n",
    "  return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "data['avg_word'] = data['Text'].apply(lambda x: avg_word(x))\n",
    "data[['Text','avg_word']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1282f7e9",
   "metadata": {},
   "source": [
    "5. Number of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f6dc977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  stopwords\n",
       "0                             @kunalb11 Im an alien          1\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...          4\n",
       "2                @joerogan @Spotify Great interview!          0\n",
       "3                    @gtera27 Doge is underestimated          1\n",
       "4  @teslacn Congratulations Tesla China for amazi...          5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "\n",
    "data['stopwords'] = data['Text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "data[['Text','stopwords']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfcae00",
   "metadata": {},
   "source": [
    "6. Number of Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea96fe77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>hastags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  hastags\n",
       "0                             @kunalb11 Im an alien        1\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...        1\n",
       "2                @joerogan @Spotify Great interview!        2\n",
       "3                    @gtera27 Doge is underestimated        1\n",
       "4  @teslacn Congratulations Tesla China for amazi...        1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['hastags'] = data['Text'].apply(lambda x: len([x for x in x.split() if x.startswith('@')]))\n",
    "data[['Text','hastags']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f133c24",
   "metadata": {},
   "source": [
    "7. Number of Numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "414f0e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>numerics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  numerics\n",
       "0                             @kunalb11 Im an alien         0\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...         0\n",
       "2                @joerogan @Spotify Great interview!         0\n",
       "3                    @gtera27 Doge is underestimated         0\n",
       "4  @teslacn Congratulations Tesla China for amazi...         0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['numerics'] = data['Text'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "data[['Text','numerics']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7712c2e",
   "metadata": {},
   "source": [
    "8. Number of Upper Case Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfde3562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  upper\n",
       "0                             @kunalb11 Im an alien      0\n",
       "1  @ID_AA_Carmack Ray tracing on Cyberpunk with H...      1\n",
       "2                @joerogan @Spotify Great interview!      0\n",
       "3                    @gtera27 Doge is underestimated      0\n",
       "4  @teslacn Congratulations Tesla China for amazi...      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['upper'] = data['Text'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "data[['Text','upper']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408b3670",
   "metadata": {},
   "source": [
    "# Pre - Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25851101",
   "metadata": {},
   "source": [
    "Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aebbc905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               @kunalb11 im an alien\n",
       "1    @id_aa_carmack ray tracing on cyberpunk with h...\n",
       "2                  @joerogan @spotify great interview!\n",
       "3                      @gtera27 doge is underestimated\n",
       "4    @teslacn congratulations tesla china for amazi...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'] = data['Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "data['Text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1655be1",
   "metadata": {},
   "source": [
    "Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a306e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiki\\AppData\\Local\\Temp/ipykernel_41220/1947507549.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['Text'] = data['Text'].str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                 kunalb11 im an alien\n",
       "1    id_aa_carmack ray tracing on cyberpunk with hd...\n",
       "2                     joerogan spotify great interview\n",
       "3                       gtera27 doge is underestimated\n",
       "4    teslacn congratulations tesla china for amazin...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'] = data['Text'].str.replace('[^\\w\\s]','')\n",
    "data['Text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4b7b41",
   "metadata": {},
   "source": [
    "Removal of Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f496b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    kunalb11 im alien\n",
       "1    id_aa_carmack ray tracing cyberpunk hdr nextle...\n",
       "2                     joerogan spotify great interview\n",
       "3                          gtera27 doge underestimated\n",
       "4    teslacn congratulations tesla china amazing ex...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "data['Text'] = data['Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "data['Text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a840dc91",
   "metadata": {},
   "source": [
    "Common word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08e91b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacex            239\n",
       "amp               218\n",
       "tesla             166\n",
       "erdayastronaut    142\n",
       "rt                127\n",
       "ppathole          123\n",
       "flcnhvy           114\n",
       "yes                86\n",
       "great              76\n",
       "teslaownerssv      73\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(data['Text']).split()).value_counts()[:10]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b182af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    kunalb11 im alien\n",
       "1    id_aa_carmack ray tracing cyberpunk hdr nextle...\n",
       "2                           joerogan spotify interview\n",
       "3                          gtera27 doge underestimated\n",
       "4    teslacn congratulations china amazing executio...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "data['Text'] = data['Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "data['Text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fd01d3",
   "metadata": {},
   "source": [
    "Rare Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05bef21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nyquil                1\n",
       "musk                  1\n",
       "negati                1\n",
       "httpstco6ohta09s5l    1\n",
       "carousel              1\n",
       "joeingeneral          1\n",
       "andrewbogut           1\n",
       "typical               1\n",
       "unusual               1\n",
       "altho                 1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(data['Text']).split()).value_counts()[-10:]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "357e245a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    kunalb11 im alien\n",
       "1    id_aa_carmack ray tracing cyberpunk hdr nextle...\n",
       "2                           joerogan spotify interview\n",
       "3                          gtera27 doge underestimated\n",
       "4    teslacn congratulations china amazing executio...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "data['Text'] = data['Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "data['Text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce20294",
   "metadata": {},
   "source": [
    "Spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e6a5c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    kunalb11 in alien\n",
       "1    id_aa_carmack ray tracing cyberpunk her nextle...\n",
       "2                           joerogan specify interview\n",
       "3                          gtera27 done underestimated\n",
       "4    teslacn congratulations china amazing executio...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'][:5].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00487719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26ad6672",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "969d6e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\saiki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c70b043a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['id_aa_carmack', 'ray', 'tracing', 'cyberpunk', 'hdr', 'nextlevel', 'tried'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(data['Text'][1]).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ea66b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\saiki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dda25b",
   "metadata": {},
   "source": [
    " Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56fc9e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    kunalb11 im alien\n",
       "1    id_aa_carmack ray trace cyberpunk hdr nextleve...\n",
       "2                           joerogan spotifi interview\n",
       "3                              gtera27 doge underestim\n",
       "4    teslacn congratul china amaz execut last year ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "data['Text'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb48d21",
   "metadata": {},
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52ffd837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "424c08f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    kunalb11 im alien\n",
       "1    id_aa_carmack ray tracing cyberpunk hdr nextle...\n",
       "2                           joerogan spotify interview\n",
       "3                          gtera27 doge underestimated\n",
       "4    teslacn congratulation china amazing execution...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'] = data['Text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "data['Text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9863a2",
   "metadata": {},
   "source": [
    "Advanced Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0045fbc7",
   "metadata": {},
   "source": [
    "N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6de11dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['kunalb11', 'im']), WordList(['im', 'alien'])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(data['Text'][0]).ngrams(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1731c0",
   "metadata": {},
   "source": [
    "Term frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec98042e",
   "metadata": {},
   "source": [
    "Term frequency is simply the ratio of the count of a word present in a sentence, to the length of the sentence.\n",
    "\n",
    "Therefore, we can generalize term frequency as:\n",
    "\n",
    "TF = (Number of times term T appears in the particular row) / (number of terms in that row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90cbadc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_aa_carmack</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ray</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tracing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cyberpunk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hdr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nextlevel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tried</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words  tf\n",
       "0  id_aa_carmack   1\n",
       "1            ray   1\n",
       "2        tracing   1\n",
       "3      cyberpunk   1\n",
       "4            hdr   1\n",
       "5      nextlevel   1\n",
       "6          tried   1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1 = (data['Text'][1:2]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
    "tf1.columns = ['words','tf']\n",
    "tf1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551e4707",
   "metadata": {},
   "source": [
    "# Inverse Document Frequency\n",
    "The intuition behind inverse document frequency (IDF) is that a word is not of much use to us if it’s appearing in all the documents.\n",
    "\n",
    "Therefore, the IDF of each word is the log of the ratio of the total number of rows to the number of rows in which that word is present.\n",
    "\n",
    "IDF = log(N/n), where, N is the total number of rows and n is the number of rows in which the word was present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f59db40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_aa_carmack</td>\n",
       "      <td>1</td>\n",
       "      <td>4.166415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ray</td>\n",
       "      <td>1</td>\n",
       "      <td>5.035453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tracing</td>\n",
       "      <td>1</td>\n",
       "      <td>7.600402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cyberpunk</td>\n",
       "      <td>1</td>\n",
       "      <td>5.115496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hdr</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nextlevel</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tried</td>\n",
       "      <td>1</td>\n",
       "      <td>5.808643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words  tf       idf\n",
       "0  id_aa_carmack   1  4.166415\n",
       "1            ray   1  5.035453\n",
       "2        tracing   1  7.600402\n",
       "3      cyberpunk   1  5.115496\n",
       "4            hdr   1  6.907255\n",
       "5      nextlevel   1  6.907255\n",
       "6          tried   1  5.808643"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i,word in enumerate(tf1['words']):\n",
    "  tf1.loc[i, 'idf'] = np.log(data.shape[0]/(len(data[data['Text'].str.contains(word)])))\n",
    "\n",
    "tf1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971a84dc",
   "metadata": {},
   "source": [
    "Term Frequency – Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5edfda62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_aa_carmack</td>\n",
       "      <td>1</td>\n",
       "      <td>4.166415</td>\n",
       "      <td>4.166415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ray</td>\n",
       "      <td>1</td>\n",
       "      <td>5.035453</td>\n",
       "      <td>5.035453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tracing</td>\n",
       "      <td>1</td>\n",
       "      <td>7.600402</td>\n",
       "      <td>7.600402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cyberpunk</td>\n",
       "      <td>1</td>\n",
       "      <td>5.115496</td>\n",
       "      <td>5.115496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hdr</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907255</td>\n",
       "      <td>6.907255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nextlevel</td>\n",
       "      <td>1</td>\n",
       "      <td>6.907255</td>\n",
       "      <td>6.907255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tried</td>\n",
       "      <td>1</td>\n",
       "      <td>5.808643</td>\n",
       "      <td>5.808643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words  tf       idf     tfidf\n",
       "0  id_aa_carmack   1  4.166415  4.166415\n",
       "1            ray   1  5.035453  5.035453\n",
       "2        tracing   1  7.600402  7.600402\n",
       "3      cyberpunk   1  5.115496  5.115496\n",
       "4            hdr   1  6.907255  6.907255\n",
       "5      nextlevel   1  6.907255  6.907255\n",
       "6          tried   1  5.808643  5.808643"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1['tfidf'] = tf1['tf'] * tf1['idf']\n",
    "tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "698e1614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1999x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7374 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
    " stop_words= 'english',ngram_range=(1,1))\n",
    "vect = tfidf.fit_transform(data['Text'])\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd813f",
   "metadata": {},
   "source": [
    "Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10893946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1999x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8020 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = \"word\")\n",
    "data_bow = bow.fit_transform(data['Text'])\n",
    "data_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f09576",
   "metadata": {},
   "source": [
    "Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e775369f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 (-0.25, 0.75)\n",
       "1                                    (0.0, 0.0)\n",
       "2                                    (0.0, 0.0)\n",
       "3                                    (0.0, 0.0)\n",
       "4    (0.20000000000000004, 0.32222222222222224)\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'][:5].apply(lambda x: TextBlob(x).sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db10a674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kunalb11 im alien</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_aa_carmack ray tracing cyberpunk hdr nextle...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joerogan spotify interview</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gtera27 doge underestimated</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>teslacn congratulation china amazing execution...</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  sentiment\n",
       "0                                  kunalb11 im alien      -0.25\n",
       "1  id_aa_carmack ray tracing cyberpunk hdr nextle...       0.00\n",
       "2                         joerogan spotify interview       0.00\n",
       "3                        gtera27 doge underestimated       0.00\n",
       "4  teslacn congratulation china amazing execution...       0.20"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'] = data['Text'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "data[['Text','sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d2415179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hastags</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>kunalb11 im alien</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>id_aa_carmack ray tracing cyberpunk hdr nextle...</td>\n",
       "      <td>13</td>\n",
       "      <td>82</td>\n",
       "      <td>5.384615</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>joerogan spotify interview</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>gtera27 doge underestimated</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>teslacn congratulation china amazing execution...</td>\n",
       "      <td>17</td>\n",
       "      <td>104</td>\n",
       "      <td>5.176471</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>1995</td>\n",
       "      <td>true sound surreal negative propaganda still e...</td>\n",
       "      <td>23</td>\n",
       "      <td>144</td>\n",
       "      <td>5.260870</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.152381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>make sure read ur term condition clicking accept</td>\n",
       "      <td>12</td>\n",
       "      <td>77</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>teslagong samwise gamgee</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>dumb dumber u0001f525u0001f525</td>\n",
       "      <td>7</td>\n",
       "      <td>59</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>progress update august 28</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               Text  \\\n",
       "0              1                                  kunalb11 im alien   \n",
       "1              2  id_aa_carmack ray tracing cyberpunk hdr nextle...   \n",
       "2              3                         joerogan spotify interview   \n",
       "3              4                        gtera27 doge underestimated   \n",
       "4              5  teslacn congratulation china amazing execution...   \n",
       "...          ...                                                ...   \n",
       "1994        1995  true sound surreal negative propaganda still e...   \n",
       "1995        1996   make sure read ur term condition clicking accept   \n",
       "1996        1997                           teslagong samwise gamgee   \n",
       "1997        1998                     dumb dumber u0001f525u0001f525   \n",
       "1998        1999                          progress update august 28   \n",
       "\n",
       "      word_count  char_count  avg_word  stopwords  hastags  numerics  upper  \\\n",
       "0              4          22  4.750000          1        1         0      0   \n",
       "1             13          82  5.384615          4        1         0      1   \n",
       "2              4          35  8.000000          0        2         0      0   \n",
       "3              4          31  7.000000          1        1         0      0   \n",
       "4             17         104  5.176471          5        1         0      0   \n",
       "...          ...         ...       ...        ...      ...       ...    ...   \n",
       "1994          23         144  5.260870         11        1         0      0   \n",
       "1995          12          77  5.500000          2        1         0      0   \n",
       "1996           4          35  8.000000          0        2         0      0   \n",
       "1997           7          59  7.571429          2        1         0      1   \n",
       "1998           4          25  5.500000          0        0         1      0   \n",
       "\n",
       "      sentiment  \n",
       "0     -0.250000  \n",
       "1      0.000000  \n",
       "2      0.000000  \n",
       "3      0.000000  \n",
       "4      0.200000  \n",
       "...         ...  \n",
       "1994   0.152381  \n",
       "1995   0.500000  \n",
       "1996   0.000000  \n",
       "1997  -0.375000  \n",
       "1998   0.000000  \n",
       "\n",
       "[1999 rows x 10 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "356caa28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "data[['Text','sentiment']].plot(ax=ax, kind='hist', xlabel='Text', ylabel=' frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cda52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
